# .github/workflows/reusable-review.yml

name: Reusable AI Code Review

on:
  workflow_call:
    inputs:
      pr_number:
        description: 'The number of the pull request'
        required: true
        type: number
      model_url:
        description: 'URL of the GGUF model to download'
        required: false
        type: string
        default: 'https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf'

permissions:
  pull-requests: write

jobs:
  code-review:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    container: ghcr.io/richard-m-j/llama.cpp:light # Or your specific image name
    env:
      MODEL_URL: ${{ inputs.model_url }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      PR_NUMBER: ${{ inputs.pr_number }}
      GH_REPO: ${{ github.repository }}

    steps:
      - name: 1. Download Diff Artifact
        uses: actions/download-artifact@v4
        with:
          name: code-diff-artifact
          path: .

      - name: 2. Generate Model URL Hash
        id: model_hash
        run: echo "hash=$(echo -n '${{ env.MODEL_URL }}' | sha256sum | cut -d' ' -f1)" >> $GITHUB_OUTPUT

      - name: 3. Cache AI Model
        id: cache-model
        uses: actions/cache@v4
        with:
          path: ./model.gguf
          key: ${{ runner.os }}-gguf-model-${{ steps.model_hash.outputs.hash }}

      - name: 4. Download AI Model if not cached
        if: steps.cache-model.outputs.cache-hit != 'true'
        run: curl -L -o ./model.gguf "${{ env.MODEL_URL }}"

      - name: 5. Construct Prompt
        run: |
          PROMPT_FILE="prompt.txt"
          SYSTEM_PROMPT="You are an expert code reviewer AI. Your task is to analyze the following code diff and provide concise, constructive feedback. Focus on potential bugs, logical errors, style violations, and areas for improved clarity or performance. Do not comment on trivial changes. Frame your feedback as helpful suggestions. Output your review in Markdown format."
          CODE_DIFF=$(cat code.diff)
          cat <<EOF > $PROMPT_FILE
          $SYSTEM_PROMPT

          Here is the code diff to review:
          \`\`\`diff
          $CODE_DIFF
          \`\`\`

          Please provide your review now.
          EOF

      - name: 6. Run LLM Inference
        id: inference
        continue-on-error: true
        run: |
          echo "Starting LLM inference... This may take a few minutes."
          /home/appuser/llama-cli \
            -m ./model.gguf \
            -f prompt.txt \
            --ctx-size 4096 \
            --n-predict 1024 \
            --temp 0.2 \
            > review_output.txt
          echo "LLM inference complete."

      - name: 7. Format and Post Comment
        # **FIX**: Use the Bash shell to support the '[[' syntax
        shell: bash
        run: |
          if [[ ${{ steps.inference.outcome }} == 'failure' ]]; then
            {
              echo "### ðŸ¤– AI Code Review Failed"
              echo ""
              echo "The AI code review could not be completed due to an error during the inference step."
            } > final_comment.md
          else
            {
              echo "### ðŸ¤– AI Code Review"
              echo ""
              echo "Here are some suggestions based on the latest changes. Please treat these as pointers for consideration, not mandates."
              echo ""
              echo "---"
              echo ""
              cat review_output.txt
            } > final_comment.md
          fi
          
          gh pr comment $PR_NUMBER --repo $GH_REPO --body-file final_comment.md